{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit classification using siamese.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P2dx7ZJ2A4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import keras\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfnNXLaw2SJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train,y_train),(X_test,y_test)=mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szEF7qvg3zoj",
        "colab_type": "code",
        "outputId": "f7497ea2-8093-400a-cc34-2925a0ffc52d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train[0].shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIUQTmCG2izB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_idxs(X):\n",
        "    idxs1=np.random.randint(0,len(X),1)[0]\n",
        "    return idxs1\n",
        "\n",
        "def same_label_index(X,Y):\n",
        "\n",
        "  while True:\n",
        "    idx1=generate_idxs(X)\n",
        "    idx2=generate_idxs(X)\n",
        "\n",
        "    if Y[idx1]==Y[idx2]:\n",
        "      break\n",
        "\n",
        "  return idx1,idx2\n",
        "\n",
        "def different_label_index(X,Y):\n",
        "  while True:\n",
        "    idx1=generate_idxs(X)\n",
        "    idx2=generate_idxs(X)\n",
        "    if Y[idx1]!=Y[idx2]:\n",
        "      break\n",
        "\n",
        "  return idx1,idx2\n",
        "\n",
        "def batch_generator_train(X,Y,batch_size):\n",
        "  while True:\n",
        "    data=[np.zeros((batch_size,28,28,1)) for i in range(2)]\n",
        "    tar=[np.zeros((batch_size,))]\n",
        "    \n",
        "    #Same pairs.\n",
        "    for i in range(0,batch_size//2):\n",
        "      idx1,idx2=same_label_index(X,Y)\n",
        "      dig1=np.expand_dims(X[idx1],axis=-1)\n",
        "      dig2=np.expand_dims(X[idx2],axis=-1)\n",
        "\n",
        "      data[0][i,:,:,:]=dig1\n",
        "      data[1][i,:,:,:]=dig2\n",
        "      tar[0][i]=1\n",
        "\n",
        "    #Different pairs\n",
        "    for j in range(batch_size//2,batch_size):\n",
        "      idx1,idx2=different_label_index(X,Y)\n",
        "      dig1=np.expand_dims(X[idx1],axis=-1)\n",
        "      dig2=np.expand_dims(X[idx2],axis=-1)\n",
        "\n",
        "      data[0][j,:,:,:]=dig1\n",
        "      data[1][j,:,:,:]=dig2\n",
        "      tar[0][j]=0\n",
        "  \n",
        "    yield data,tar\n",
        "\n",
        "def batch_generator_test(X,Y,batch_size):\n",
        "  while True:\n",
        "    data=[np.zeros((batch_size,28,28,1)) for i in range(2)]\n",
        "    tar=[np.zeros((batch_size,))]\n",
        "    \n",
        "    #Same pairs.\n",
        "    for i in range(0,batch_size//2):\n",
        "      idx1,idx2=same_label_index(X,Y)\n",
        "      dig1=np.expand_dims(X[idx1],axis=-1)\n",
        "      dig2=np.expand_dims(X[idx2],axis=-1)\n",
        "\n",
        "      data[0][i,:,:,:]=dig1\n",
        "      data[1][i,:,:,:]=dig2\n",
        "      tar[0][i]=1\n",
        "\n",
        "    #Different pairs\n",
        "    for j in range(batch_size//2,batch_size):\n",
        "      idx1,idx2=different_label_index(X,Y)\n",
        "      dig1=np.expand_dims(X[idx1],axis=-1)\n",
        "      dig2=np.expand_dims(X[idx2],axis=-1)\n",
        "\n",
        "      data[0][j,:,:,:]=dig1\n",
        "      data[1][j,:,:,:]=dig2\n",
        "      tar[0][j]=0\n",
        "  \n",
        "    yield data,tar\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxKDjkWF8Q39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_tr,y_tr=next(batch_generator_train(X_train,y_train,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm-ackuY-bJq",
        "colab_type": "code",
        "outputId": "3e3cc5fd-988b-4388-c1a8-2a51971e5adb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_tr[0][5]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au8GF7598qds",
        "colab_type": "code",
        "outputId": "593c8e28-2698-46fb-c437-fb9ce8243904",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f = plt.figure()\n",
        "f.add_subplot(1,2, 1)\n",
        "img1=X_tr[0][5,:,:,:]\n",
        "img1=np.squeeze(img1,axis=2)\n",
        "plt.imshow(img1)\n",
        "\n",
        "f.add_subplot(1,2, 2)\n",
        "img2=X_tr[1][5,:,:,:]\n",
        "img2=np.squeeze(img2,axis=2)\n",
        "plt.imshow(img2)\n",
        "\n",
        "plt.show(block=True)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAC4CAYAAAD61bdSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuOo6UbYAhnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Conv2D,MaxPool2D,Dense,GlobalAvgPool2D,Lambda,Input,Dropout\n",
        "import keras.backend as K\n",
        "def build_model(input_shape):\n",
        "\n",
        " model=Sequential()\n",
        " model.add(Conv2D(32,(5,5),input_shape=input_shape,activation='relu'))\n",
        " model.add(Dropout(0.1))\n",
        " model.add(MaxPool2D(2,2))\n",
        " \n",
        "\n",
        " model.add(Conv2D(64,(3,3),activation='relu'))\n",
        " model.add(Dropout(0.2))\n",
        " model.add(MaxPool2D(2,2))\n",
        "\n",
        " model.add(Conv2D(64,(3,3),activation='relu'))\n",
        " model.add(Dropout(0.1))\n",
        " model.add(MaxPool2D(2,2))\n",
        "\n",
        " model.add(GlobalAvgPool2D())\n",
        " \n",
        " input1=Input(input_shape)\n",
        " input2=Input(input_shape)\n",
        " \n",
        " encoder_l=model(input1)\n",
        " encoder_r=model(input2)\n",
        "\n",
        " L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
        " L1_distance = L1_layer([encoder_l, encoder_r])\n",
        "\n",
        " output=Dense(1,activation='sigmoid')(L1_distance)\n",
        " siamese=Model(inputs=[input1,input2],outputs=output)\n",
        "\n",
        " return siamese\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKOB3N35EZcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "siamese_model=build_model((28,28,1))\n",
        "siamese_model.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.001))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LNkiBZHFGNq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f43251c5-d8cc-4b55-ec1a-38b43da4471b"
      },
      "source": [
        "history=siamese_model.fit_generator(batch_generator_train(X_train,y_train,2),steps_per_epoch=150,validation_data=batch_generator_test(X_test,y_test,2),\n",
        "                                    validation_steps=50,epochs=50,shuffle=True)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "150/150 [==============================] - 4s 28ms/step - loss: 4.9719 - val_loss: 2.1934\n",
            "Epoch 2/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 2.9071 - val_loss: 1.8108\n",
            "Epoch 3/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 2.9638 - val_loss: 1.5178\n",
            "Epoch 4/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 1.9713 - val_loss: 1.1874\n",
            "Epoch 5/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 1.0383 - val_loss: 0.8961\n",
            "Epoch 6/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 1.0616 - val_loss: 0.6237\n",
            "Epoch 7/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 1.0250 - val_loss: 0.5853\n",
            "Epoch 8/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 1.1807 - val_loss: 0.6836\n",
            "Epoch 9/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.7360 - val_loss: 0.5753\n",
            "Epoch 10/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.7339 - val_loss: 0.5957\n",
            "Epoch 11/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.6625 - val_loss: 0.5635\n",
            "Epoch 12/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.5638 - val_loss: 0.5771\n",
            "Epoch 13/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.6321 - val_loss: 0.4517\n",
            "Epoch 14/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.5802 - val_loss: 0.4942\n",
            "Epoch 15/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.5975 - val_loss: 0.5245\n",
            "Epoch 16/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.5698 - val_loss: 0.6659\n",
            "Epoch 17/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.6944 - val_loss: 0.5405\n",
            "Epoch 18/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.5078 - val_loss: 0.5406\n",
            "Epoch 19/50\n",
            "150/150 [==============================] - 2s 12ms/step - loss: 0.5076 - val_loss: 0.4587\n",
            "Epoch 20/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.5527 - val_loss: 0.4844\n",
            "Epoch 21/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.5180 - val_loss: 0.4016\n",
            "Epoch 22/50\n",
            "150/150 [==============================] - 2s 12ms/step - loss: 0.5368 - val_loss: 0.4900\n",
            "Epoch 23/50\n",
            "150/150 [==============================] - 2s 12ms/step - loss: 0.4997 - val_loss: 0.4251\n",
            "Epoch 24/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.5154 - val_loss: 0.4347\n",
            "Epoch 25/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.5126 - val_loss: 0.4883\n",
            "Epoch 26/50\n",
            "150/150 [==============================] - 2s 12ms/step - loss: 0.4458 - val_loss: 0.4229\n",
            "Epoch 27/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.6602 - val_loss: 0.5296\n",
            "Epoch 28/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.5160 - val_loss: 0.3879\n",
            "Epoch 29/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.4380 - val_loss: 0.3975\n",
            "Epoch 30/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.5006 - val_loss: 0.3990\n",
            "Epoch 31/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.4514 - val_loss: 0.4791\n",
            "Epoch 32/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.4990 - val_loss: 0.4536\n",
            "Epoch 33/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.5596 - val_loss: 0.4275\n",
            "Epoch 34/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.4990 - val_loss: 0.3703\n",
            "Epoch 35/50\n",
            "150/150 [==============================] - 2s 12ms/step - loss: 0.4416 - val_loss: 0.4425\n",
            "Epoch 36/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.4705 - val_loss: 0.3809\n",
            "Epoch 37/50\n",
            "150/150 [==============================] - 2s 12ms/step - loss: 0.5112 - val_loss: 0.3934\n",
            "Epoch 38/50\n",
            "150/150 [==============================] - 2s 12ms/step - loss: 0.5413 - val_loss: 0.4027\n",
            "Epoch 39/50\n",
            "150/150 [==============================] - 2s 12ms/step - loss: 0.5054 - val_loss: 0.4538\n",
            "Epoch 40/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.4740 - val_loss: 0.4433\n",
            "Epoch 41/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.4635 - val_loss: 0.4210\n",
            "Epoch 42/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.4209 - val_loss: 0.3532\n",
            "Epoch 43/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.4090 - val_loss: 0.3704\n",
            "Epoch 44/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.4907 - val_loss: 0.4535\n",
            "Epoch 45/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.4689 - val_loss: 0.4136\n",
            "Epoch 46/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.3435 - val_loss: 0.3121\n",
            "Epoch 47/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.4280 - val_loss: 0.3586\n",
            "Epoch 48/50\n",
            "150/150 [==============================] - 2s 12ms/step - loss: 0.5155 - val_loss: 0.4614\n",
            "Epoch 49/50\n",
            "150/150 [==============================] - 2s 12ms/step - loss: 0.4670 - val_loss: 0.4099\n",
            "Epoch 50/50\n",
            "150/150 [==============================] - 2s 11ms/step - loss: 0.4124 - val_loss: 0.3538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr-E12v7LeEP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "53fab8e0-b344-401a-a6f0-911e0e0cdef5"
      },
      "source": [
        "idx1,idx2=same_label_index(X_test,y_test)\n",
        "X1=[np.zeros((1,28,28,1)) for i in range(2)]\n",
        "X1[0][0,:,:,:]=np.expand_dims(X_test[idx1],axis=-1)\n",
        "X1[1][0,:,:,:]=np.expand_dims(X_test[idx2],axis=-1)\n",
        "\n",
        "idx1,idx2=different_label_index(X_test,y_test)\n",
        "X2=[np.zeros((1,28,28,1)) for i in range(2)]\n",
        "X2[0][0,:,:,:]=np.expand_dims(X_test[idx1],axis=-1)\n",
        "X2[1][0,:,:,:]=np.expand_dims(X_test[idx2],axis=-1)\n",
        "\n",
        "print(siamese_model.predict(X1))\n",
        "print(siamese_model.predict(X2))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.75682765]]\n",
            "[[0.21019356]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}